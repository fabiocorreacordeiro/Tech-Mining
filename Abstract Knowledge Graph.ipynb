{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gensim\n",
    "import nltk\n",
    "from  nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.models import ColumnDataSource, LabelSet, LayoutDOM, Plot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.core.properties import Instance, String\n",
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando base concatenada e misturando os artigos para evitar que haja um viés devido a ordem de leitura dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_OG = pd.read_json(\"Elsevier_abstract - Consolidado.json\")\n",
    "# Misturando as linhas e resetando o index\n",
    "abstract_OG = abstract_OG.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35342"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contando os documentos\n",
    "print(\"Núlen(abstract_OG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando palavras e espaços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando as palavras \"Abstract\", \"Unknown\", \"Publisher Summary\", \"Summary\", \"Fundamento\"\n",
    "# que aparece no início de vários textos\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].str.replace(\"Abstract\", \"\")\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].str.replace(\"Unknown\", \"\")\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].str.replace(\"Publisher Summary\", \"\")\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].str.replace(\"Summary\", \"\")\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].str.replace(\"Fundamento\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o texto em uma lista de palavras desconsiderando espaços e \\n\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].str.split()      \n",
    "# Unificando a lista de palavras usando espaços simples\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar as linhas sem Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstract_OG = abstract_OG[abstract_OG[\"Abstract\"] != \"\"]\n",
    "#abstract_OG = abstract_OG.reset_index()\n",
    "#abstract_OG = abstract_OG.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando o pré-processamento simple do Gensim basicamente para gerar os tokens dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas de stopwords\n",
    "#nltk.download('stopwords')\n",
    "# Mapeando stopwords com NLTK\n",
    "#stopwordsIngles = stopwords.words(\"english\")\n",
    "\n",
    "#def remove_stopwords(abstract):\n",
    "#    without_stopwords = []\n",
    "#    for word in abstract:\n",
    "#        if word not in stopwordsIngles:\n",
    "#            without_stopwords.append(word)\n",
    "#    return(without_stopwords)\n",
    "    \n",
    "# Excluindo stopwords\n",
    "#abstract_OG[\"Abstract\"] = abstract_OG[\"Abstract\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer pré-processamento das keywords e Creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artigos pré-processados:  1000\n",
      "Artigos pré-processados:  2000\n",
      "Artigos pré-processados:  3000\n",
      "Artigos pré-processados:  4000\n",
      "Artigos pré-processados:  5000\n",
      "Artigos pré-processados:  6000\n",
      "Artigos pré-processados:  7000\n",
      "Artigos pré-processados:  8000\n",
      "Artigos pré-processados:  9000\n",
      "Artigos pré-processados:  10000\n",
      "Artigos pré-processados:  11000\n",
      "Artigos pré-processados:  12000\n",
      "Artigos pré-processados:  13000\n",
      "Artigos pré-processados:  14000\n",
      "Tempo total decorrido:  4:59:56.925988\n"
     ]
    }
   ],
   "source": [
    "#Procurar \"keyword\" e \"creator\" em todos os artigos de O&G\n",
    "\n",
    "#momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "#n = 0\n",
    "\n",
    "#for index, row in abstract_OG.iterrows():\n",
    "#    n = n+1\n",
    "#    preprocess_key = []\n",
    "#    preprocess_creator = []\n",
    "    \n",
    "#    row_keywords = row[\"Keywords\"]  # Selecionar keywords\n",
    "#    for word in row_keywords:       # Looping em cada keyword\n",
    "#        word = word.strip()         # Retirando espaços em branco\n",
    "#        word = word.lower()         # Todas letras em minúsculo\n",
    "#        preprocess_key.append(word)\n",
    "        \n",
    "#    row_creators = row[\"Creator\"]   # Selecionar autores\n",
    "#    for word in row_creators:       # Looping em cada keyword\n",
    "#        word = word.strip()         # Retirando espaços em branco\n",
    "#        word = word.lower()         # Todas letras em minúsculo\n",
    "#        preprocess_creator.append(word)\n",
    "        \n",
    "#    abstract_OG[\"Keywords\"][index] = preprocess_key\n",
    "#    abstract_OG[\"Creator\"][index] = preprocess_creator\n",
    "\n",
    "#    if n%1000 == 0:\n",
    "#        print (\"Artigos pré-processados: \", n)\n",
    "        \n",
    "#momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "#print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gravando arquivo Pré-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstract_OG.to_json(\"Elsevier_abstract - Preprocessado.json\", date_format = 'iso')\n",
    "abstract_OG = pd.read_json(\"Elsevier_abstract - Preprocessado.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorizando os documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando os modelos Doc2Vec utilizando os artigos provenientes do conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total decorrido:  0:09:10.297600\n"
     ]
    }
   ],
   "source": [
    "momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "# Todos os documentos devem passar pela função TaggedDocument antes de ser vetorizado\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(abstract_OG[\"Abstract\"])]\n",
    "\n",
    "#Hiperparâmetros do modelo Doc2Vec\n",
    "Abstract_doc2vec = Doc2Vec(documents,\n",
    "                           vector_size=8,\n",
    "                           dm=1,\n",
    "                           window=5,\n",
    "                           min_count=250,\n",
    "                           workers=7,\n",
    "                           epochs=300,\n",
    "                           alpha=0.025,\n",
    "                           min_alpha=0.00025)\n",
    "\n",
    "momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravando modelo Doc2Vec\n",
    "fname = \"AbstractKG_doc2vec_model\"\n",
    "Abstract_doc2vec.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo modelo Doc2Vec\n",
    "fname = \"AbstractKG_doc2vec_model\"\n",
    "Abstract_doc2vec = Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total decorrido:  0:07:21.377400\n"
     ]
    }
   ],
   "source": [
    "# Utilizar o modelo Doc2Vec gerado para inferir os vetores para todos os artigos.\n",
    "\n",
    "momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "abstract_OG[\"Doc2Vec\"] = abstract_OG[\"Abstract\"].apply(Abstract_doc2vec.infer_vector)\n",
    "\n",
    "momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gravando arquivo com Doc2Vec inferido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_OG.to_json(\"Elsevier_abstract - Preprocessado.json\", date_format = 'iso')\n",
    "abstract_OG = pd.read_json(\"Elsevier_abstract - Preprocessado.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract  (0, 1.0) ---->  A Wide-Bandwidth Ultrasonic Study of Suspensions: The Variation of Velocity and Attenuation with Particle Size \n",
      "Abstract  (9970, 0.9701407551765442) ---->  Anaerobic biodegradability testing of surfactants \n",
      "Abstract  (14098, 0.9677221179008484) ---->  Fullerene grafted hydrocarbon polymers \n",
      "Abstract  (7425, 0.9658060669898987) ---->  The economic control of quality \n",
      "Abstract  (10188, 0.9613857865333557) ---->  Valence force calculation of the vibrational spectra of crystalline isotactic polypropylene and some deuterated polypropylenes \n",
      "Abstract  (1, 0.9543232917785645) ---->  Elongation and subsequent relaxation measurements on dilute polyisobutylene solutions \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# Retornando um exemplo com os 6 documentos mais similares (o próprio + top5)\n",
    "top5 = Abstract_doc2vec.docvecs.most_similar([Abstract_doc2vec.docvecs[0]], topn=6)\n",
    "for n in top5:\n",
    "    print(\"Abstract \", n, \"----> \", abstract_OG.loc[n[0]][\"Title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorizando as keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção serão gerados vetores para as principais keywords que aparecem nos artigos de O&G. Para tal, será gerado uma lista de keywords. Para cada keyword dessa lista serão identificados e concatenados os abstracts a qual essa keyword está relacionada. O vetor da keyword será o vetor Doc2Vec inferido para o texto dos abstracts concatenados utilizado o modelo já treinado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando as keywords de O&G que parecem mais de 5 vezes\n",
    "\n",
    "# frequência mínima para uma keyword ser considerada\n",
    "#min_freq = 6 \n",
    "# Separando os artigos de O&G\n",
    "#keyword_list = abstract_OG\n",
    "#keywords = []\n",
    "\n",
    "# Incluindo keywords de cada artigo na lista \"keywords\"\n",
    "#keyword_list[\"Keywords\"].apply(keywords.extend)               \n",
    "\n",
    "# Criando DataFrame com a frequência das keywords\n",
    "#keywords = pd.Series(keywords)\n",
    "#keywords = pd.DataFrame(data={\"Frequency\": keywords.value_counts()})\n",
    "# Retirand as keywords com Frequência menor do que min_freq\n",
    "#keywords = keywords[keywords[\"Frequency\"] >= min_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando todos os abstracts de uma mesma keyword\n",
    "\n",
    "#momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "# Criando DataFrame para armazenar os Abstracts concatenados das keywords\n",
    "#keyword_vectors = pd.DataFrame(columns=['Keywords', 'Abstracts'])\n",
    "\n",
    "# Fazer uma iteração para todas as keywords\n",
    "#for key in keywords.index:\n",
    "#    abstracts = []\n",
    "      \n",
    "     #Procurar a keyword em todos os artigos de O&G\n",
    "#    for index, row in abstract_OG.iterrows():\n",
    "\n",
    "        # Verificar se a Keyword procurada está nesse artigo\n",
    "#        if key in row[\"Keywords\"]:\n",
    "            # Concatenar abstracts\n",
    "#            abstracts.extend(row[\"Abstract\"])\n",
    "     \n",
    "    # Incluir linha no DataFrame \"keyword_vectors\"\n",
    "#    keyword_vectors = keyword_vectors.append({'Keywords': key, 'Abstracts': abstracts}, ignore_index=True)\n",
    "    \n",
    "#momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "#print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para não precisar repetir as etapas anteriores (separar keywords e concatenar os textos) lemos diretamento do disco\n",
    "keyword_vectors = pd.read_json(\"Elsevier_abstract - Keywords.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total decorrido:  0:06:56.420000\n"
     ]
    }
   ],
   "source": [
    "# Utilizando o modelo já treinado inferir os vetores para as keywords\n",
    "momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "keyword_vectors[\"Doc2Vec\"] = keyword_vectors[\"Abstracts\"].apply(Abstract_doc2vec.infer_vector)\n",
    "\n",
    "momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando e lendo em disco a lista de keyword com abstracts\n",
    "keyword_vectors.to_json(\"Elsevier_abstract - Keywords.json\", date_format = 'iso')\n",
    "keyword_vectors = pd.read_json(\"Elsevier_abstract - Keywords.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstracts</th>\n",
       "      <th>Doc2Vec</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[the, co, capture, project, ccp, phase, progra...</td>\n",
       "      <td>[3.0489015579, 4.9259805679, 0.7291272879, 0.8...</td>\n",
       "      <td>co2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[this, study, deals, with, the, application, o...</td>\n",
       "      <td>[1.2594091892, 1.9156749249, -0.6412436366, -0...</td>\n",
       "      <td>modelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[process, evaluation, of, aucl, mg, ph, donor,...</td>\n",
       "      <td>[2.3217506409, 0.5866640806, 2.0094738007, 3.6...</td>\n",
       "      <td>kinetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[this, paper, documents, the, discovery, of, f...</td>\n",
       "      <td>[3.5142683983, 3.5081384182, 1.441160202, -4.2...</td>\n",
       "      <td>overpressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[although, the, term, naphthenic, acids, was, ...</td>\n",
       "      <td>[-2.4418046474, 1.4438048601, -1.8562635183, 0...</td>\n",
       "      <td>mass spectrometry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Abstracts  \\\n",
       "0    [the, co, capture, project, ccp, phase, progra...   \n",
       "1    [this, study, deals, with, the, application, o...   \n",
       "10   [process, evaluation, of, aucl, mg, ph, donor,...   \n",
       "100  [this, paper, documents, the, discovery, of, f...   \n",
       "101  [although, the, term, naphthenic, acids, was, ...   \n",
       "\n",
       "                                               Doc2Vec           Keywords  \n",
       "0    [3.0489015579, 4.9259805679, 0.7291272879, 0.8...                co2  \n",
       "1    [1.2594091892, 1.9156749249, -0.6412436366, -0...          modelling  \n",
       "10   [2.3217506409, 0.5866640806, 2.0094738007, 3.6...           kinetics  \n",
       "100  [3.5142683983, 3.5081384182, 1.441160202, -4.2...       overpressure  \n",
       "101  [-2.4418046474, 1.4438048601, -1.8562635183, 0...  mass spectrometry  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_vectors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É necessário reduzir a dimensionalidade dos vetores de 50 para 2 para conseguir gerar uma visualização. Será utilizado o algoritmo tSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzindo de 50 dimensões para 2 usando tSNE para permitir a plotagem\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=12,early_exaggeration=10  )\n",
    "embed_tsne = tsne.fit_transform(keyword_vectors[\"Doc2Vec\"].tolist())\n",
    "embed_tsne = pd.DataFrame(data=embed_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo uma função que recebe os vetores já reduzidos para duas dimensões e plota o gráfico\n",
    "def scater_plot(embed_tsne, vocabulario, color):\n",
    "    p = figure(tools=\"pan,wheel_zoom,reset\",#save\",\n",
    "               toolbar_location=\"above\",\n",
    "               title=\" \",\n",
    "               plot_width=800, \n",
    "               plot_height=500)\n",
    "\n",
    "    source = ColumnDataSource(data=dict(x1=embed_tsne[0],\n",
    "                                        x2=embed_tsne[1],\n",
    "                                        names=vocabulario))\n",
    "\n",
    "    p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, color=color)\n",
    "\n",
    "    labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                      text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                      source=source, text_align='center')\n",
    "    p.add_layout(labels)\n",
    "    bokeh.io.output_notebook(INLINE) \n",
    "    output_notebook()\n",
    "    show(p)\n",
    "    return()\n",
    "\n",
    "# Plotando o grafico\n",
    "scater_plot(embed_tsne, keyword_vectors[\"Keywords\"], 'CornflowerBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorizando os autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mesma técnica utilizada para se criar os vetores das Keywords será utilizada para se vetorizar os autores dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando autores de O&G que parecem mais de 5 vezes\n",
    "\n",
    "# frequência mínima para um autor ser considerada\n",
    "#min_freq = 6\n",
    "# Separando os artigos de O&G\n",
    "#creator_list = abstract_OG\n",
    "#creators = []\n",
    "# Incluindo autor de cada artigo na lista \"creators\"\n",
    "#creator_list[\"Creator\"].apply(creators.extend)               \n",
    "\n",
    "# Criando DataFrame com a frequência dos autores\n",
    "#creators = pd.Series(creators)\n",
    "#creators = pd.DataFrame(data={\"Frequency\": creators.value_counts()})\n",
    "# Retirand as keywords com Frequência menor do que min_freq\n",
    "#creators = creators[creators[\"Frequency\"] >= min_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando todos os abstracts de um mesmo autor\n",
    "\n",
    "#momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "# Criando DataFrame para armazenar os Abstracts concatenados dos autores\n",
    "#creator_vectors = pd.DataFrame(columns=['Creator', 'Abstracts'])\n",
    "\n",
    "# Fazer uma iteração para todos os autores\n",
    "#for key in creators.index:\n",
    "    \n",
    "#    abstracts = []\n",
    "    \n",
    "    #Procurar os autores em todos os artigos de O&G\n",
    "#    for index, row in abstract_OG.iterrows():\n",
    "\n",
    "        # Verificar se o autor procurado está nesse artigo\n",
    "#        if key in row[\"Creator\"]:\n",
    "            # Concatenar abstracts\n",
    "#            abstracts.extend(row[\"Abstract\"])\n",
    "     \n",
    "    # Incluir linha no DataFrame \"creator_vectors\"\n",
    "#    creator_vectors = creator_vectors.append({'Creator': key, 'Abstracts': abstracts}, ignore_index=True)\n",
    "    \n",
    "#momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "#print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para não precisar repetir as etapas anteriores (separar autores e concatenar os textos) lemos diretamento do disco\n",
    "creator_vectors = pd.read_json(\"Elsevier_abstract - Creators.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(creator_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total decorrido:  0:03:59.220000\n"
     ]
    }
   ],
   "source": [
    "# Utilizando o modelo já treinado inferir os vetores para os autores\n",
    "momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "creator_vectors[\"Doc2Vec\"] = creator_vectors[\"Abstracts\"].apply(Abstract_doc2vec.infer_vector)\n",
    "\n",
    "momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando e lendo em disco a lista de autores com abstracts\n",
    "creator_vectors.to_json(\"Elsevier_abstract - Creators.json\", date_format = 'iso')\n",
    "creator_vectors = pd.read_json(\"Elsevier_abstract - Creators.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstracts</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Doc2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[complexes, of, and, aminopyridine, with, the,...</td>\n",
       "      <td>gerrard, d.l.</td>\n",
       "      <td>[0.1216731519, -1.1021842957, 4.7513136864, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[complexes, of, and, aminopyridine, with, the,...</td>\n",
       "      <td>allan, j.r.</td>\n",
       "      <td>[1.0570453405, 0.12217671420000001, 5.93484735...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[small, angle, neutron, scattering, has, been,...</td>\n",
       "      <td>peiffer, d.g.</td>\n",
       "      <td>[0.6661279202, -7.5089697838, 2.51254320139999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[dijet, angular, distributions, from, the, fir...</td>\n",
       "      <td>liang, z.</td>\n",
       "      <td>[-1.2167836428, -6.4154033661, -7.2966299057, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[the, chemisorption, and, thermal, decompositi...</td>\n",
       "      <td>gland, j.l.</td>\n",
       "      <td>[3.8563585281, -5.672191143, 4.7051215172, 8.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Abstracts        Creator  \\\n",
       "0    [complexes, of, and, aminopyridine, with, the,...  gerrard, d.l.   \n",
       "1    [complexes, of, and, aminopyridine, with, the,...    allan, j.r.   \n",
       "10   [small, angle, neutron, scattering, has, been,...  peiffer, d.g.   \n",
       "100  [dijet, angular, distributions, from, the, fir...      liang, z.   \n",
       "101  [the, chemisorption, and, thermal, decompositi...    gland, j.l.   \n",
       "\n",
       "                                               Doc2Vec  \n",
       "0    [0.1216731519, -1.1021842957, 4.7513136864, 4....  \n",
       "1    [1.0570453405, 0.12217671420000001, 5.93484735...  \n",
       "10   [0.6661279202, -7.5089697838, 2.51254320139999...  \n",
       "100  [-1.2167836428, -6.4154033661, -7.2966299057, ...  \n",
       "101  [3.8563585281, -5.672191143, 4.7051215172, 8.6...  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator_vectors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É necessário reduzir a dimensionalidade dos vetores de 100 para 2 para conseguir gerar uma visualização. Será utilizado o algoritmo tSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzindo de 100 dimensões para 2 usando tSNE para permitir a plotagem\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=12,early_exaggeration=10  )\n",
    "embed_tsne = tsne.fit_transform(creator_vectors[\"Doc2Vec\"].tolist())\n",
    "embed_tsne = pd.DataFrame(data=embed_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Plotando o grafico\n",
    "scater_plot(embed_tsne, creator_vectors[\"Creator\"], 'CornflowerBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unindo os diversos vetores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção será criado um dataframe com os três tipos de vetores: artigo, keyword e autor. Dessa forma, essas três entidades poderão ser analisadas no mesmo espaço vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o dataframe multi_vector que irá receber os três tipos de vetores\n",
    "multi_vector = pd.DataFrame(columns=['Type_vec', 'Description', 'Doc2Vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando os vetores dos artigos no multi_vector\n",
    "multi_vector_article = pd.DataFrame(columns=['Type_vec', 'Description', 'Doc2Vec', 'Date', 'Affiliate'])\n",
    "multi_vector_article [['Description', \n",
    "                       'Doc2Vec', \n",
    "                       'Date', \n",
    "                       'Affiliate']] = abstract_OG[['Title', \n",
    "                                                    'Doc2Vec', \n",
    "                                                    'Date', \n",
    "                                                    'Affiliate']]\n",
    "#multi_vector_article ['Doc2Vec']= abstract_OG['Doc2Vec']\n",
    "multi_vector_article['Type_vec'] = 'Article'\n",
    "multi_vector_article = multi_vector_article#.head(1000)\n",
    "multi_vector = pd.concat([multi_vector, multi_vector_article], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando os vetores das keywords no multi_vector\n",
    "multi_vector_keyword = pd.DataFrame(columns=['Type_vec', 'Description', 'Doc2Vec'])\n",
    "multi_vector_keyword [['Description', 'Doc2Vec']]= keyword_vectors[['Keywords', 'Doc2Vec']]\n",
    "multi_vector_keyword['Type_vec'] = 'Keywords'\n",
    "multi_vector = pd.concat([multi_vector, multi_vector_keyword], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando os vetores dos autores no multi_vector\n",
    "multi_vector_creator = pd.DataFrame(columns=['Type_vec', 'Description', 'Doc2Vec'])\n",
    "multi_vector_creator [['Description', 'Doc2Vec']]= creator_vectors[['Creator', 'Doc2Vec']]\n",
    "multi_vector_creator['Type_vec'] = 'Creator'\n",
    "multi_vector = pd.concat([multi_vector, multi_vector_creator], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total decorrido:  0:07:03.169000\n"
     ]
    }
   ],
   "source": [
    "# Reduzindo de 100 dimensões para 2 usando tSNE para permitir a plotagem\n",
    "momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=12,early_exaggeration=10  )\n",
    "embed_tsne = tsne.fit_transform(multi_vector[\"Doc2Vec\"].tolist())\n",
    "embed_tsne = pd.DataFrame(data=embed_tsne)\n",
    "\n",
    "momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acrescentando as duas dimensões do tSNE no dataframe\n",
    "multi_vector[\"TSNE_1\"] = embed_tsne[0]\n",
    "multi_vector[\"TSNE_2\"] = embed_tsne[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gravando o dataframe\n",
    "multi_vector.to_csv(\"Elsevier_abstract - Multivector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affiliate</th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Doc2Vec</th>\n",
       "      <th>Type_vec</th>\n",
       "      <th>TSNE_1</th>\n",
       "      <th>TSNE_2</th>\n",
       "      <th>DisQuery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>oil</td>\n",
       "      <td>[-0.4282711744, 2.7900283337, -2.6506662369000...</td>\n",
       "      <td>Keywords</td>\n",
       "      <td>23.724588</td>\n",
       "      <td>-54.072781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>Petrobras</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>Advanced performance evaluation of a reverse o...</td>\n",
       "      <td>[0.1258293688, 6.7627344131000005, -6.18596124...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-0.898239</td>\n",
       "      <td>-9.343952</td>\n",
       "      <td>0.048916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10610</th>\n",
       "      <td>Shell</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>Economics of steam-assisted gravity drainage f...</td>\n",
       "      <td>[-0.6078539491, 3.3439757824, -4.8164253235, -...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-19.555229</td>\n",
       "      <td>-19.973049</td>\n",
       "      <td>0.049188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7743</th>\n",
       "      <td>Statoil</td>\n",
       "      <td>1999-04-30</td>\n",
       "      <td>Chemical and Ecotoxicological Characterisation...</td>\n",
       "      <td>[-3.4217646122, 3.2996394634, -6.9708566666, -...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-31.787167</td>\n",
       "      <td>26.226465</td>\n",
       "      <td>0.058726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7538</th>\n",
       "      <td>Eni</td>\n",
       "      <td>2008-02-15</td>\n",
       "      <td>Structure of waxy crude oil emulsion gels</td>\n",
       "      <td>[-0.1932552606, 3.2740831375, -1.7274987698, -...</td>\n",
       "      <td>Article</td>\n",
       "      <td>24.381937</td>\n",
       "      <td>-54.424145</td>\n",
       "      <td>0.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Exxon</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>Characterizing PM2.5 emission profiles for sta...</td>\n",
       "      <td>[-2.3404331207, 7.1500716209, -6.321516037, 0....</td>\n",
       "      <td>Article</td>\n",
       "      <td>-0.975951</td>\n",
       "      <td>-9.051226</td>\n",
       "      <td>0.064043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>classification</td>\n",
       "      <td>[-3.6147005558, 4.3121452332, -4.9571299553, -...</td>\n",
       "      <td>Keywords</td>\n",
       "      <td>-31.555269</td>\n",
       "      <td>26.176226</td>\n",
       "      <td>0.069877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>produced water</td>\n",
       "      <td>[-1.1359440088000001, 3.6240203381000002, -4.9...</td>\n",
       "      <td>Keywords</td>\n",
       "      <td>-34.611584</td>\n",
       "      <td>27.184467</td>\n",
       "      <td>0.072928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>Shell</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>Well-to-wake energy and greenhouse gas analysi...</td>\n",
       "      <td>[-1.0872951746, 4.3649663925, -5.7739739418, 2...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-0.774618</td>\n",
       "      <td>-9.366707</td>\n",
       "      <td>0.072934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>petroleum</td>\n",
       "      <td>[-0.2437291741, 3.0880243778, -1.3117181063, -...</td>\n",
       "      <td>Keywords</td>\n",
       "      <td>23.377129</td>\n",
       "      <td>-54.102676</td>\n",
       "      <td>0.080275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9249</th>\n",
       "      <td>Statoil</td>\n",
       "      <td>1992-04-30</td>\n",
       "      <td>IOR resource potential of Norwegian North Sea ...</td>\n",
       "      <td>[0.5740600824000001, 6.1507005692, -1.58802568...</td>\n",
       "      <td>Article</td>\n",
       "      <td>24.581907</td>\n",
       "      <td>-56.005833</td>\n",
       "      <td>0.081228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>Exxon</td>\n",
       "      <td>1989-04-30</td>\n",
       "      <td>BEB-operated thermal projects: Comparison of p...</td>\n",
       "      <td>[-1.8900097609, 6.6728649139, -3.799053669, 0....</td>\n",
       "      <td>Article</td>\n",
       "      <td>-61.596748</td>\n",
       "      <td>-6.843457</td>\n",
       "      <td>0.082111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5066</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1989-04-30</td>\n",
       "      <td>BEB-operated thermal projects: Comparison of p...</td>\n",
       "      <td>[-1.6470646858, 6.555706501, -3.76441764830000...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-61.593414</td>\n",
       "      <td>-6.847637</td>\n",
       "      <td>0.083048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>liquefaction</td>\n",
       "      <td>[0.9881038666, 2.7050681114, -1.1644713879, -0...</td>\n",
       "      <td>Keywords</td>\n",
       "      <td>23.251734</td>\n",
       "      <td>-54.073257</td>\n",
       "      <td>0.089425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>Shell</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>The effect of oxygenate fuels on PN emissions ...</td>\n",
       "      <td>[-1.5451220274000002, 2.6626803875, -8.0992641...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-1.872740</td>\n",
       "      <td>-9.519087</td>\n",
       "      <td>0.092262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>Total</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>High pressure viscosity characterization of fo...</td>\n",
       "      <td>[1.3301105499, 2.3850858212, -2.1765749454, -0...</td>\n",
       "      <td>Article</td>\n",
       "      <td>25.023630</td>\n",
       "      <td>-53.527313</td>\n",
       "      <td>0.097174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12750</th>\n",
       "      <td>Shell</td>\n",
       "      <td>2001-12-31</td>\n",
       "      <td>Aqueous leaching of polycyclic aromatic hydroc...</td>\n",
       "      <td>[-1.3535658121, 2.0455274582, -3.5550067425, 0...</td>\n",
       "      <td>Article</td>\n",
       "      <td>36.183414</td>\n",
       "      <td>-29.160728</td>\n",
       "      <td>0.101593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>Shell</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>Demonstrating the fuel economy potential of pa...</td>\n",
       "      <td>[-4.2701740265, 5.058816433, -5.986205101, 0.9...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-58.066982</td>\n",
       "      <td>-5.225783</td>\n",
       "      <td>0.104546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>Total</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>Filterability of oil sands tailings</td>\n",
       "      <td>[1.0330308676, 2.9685220718, -1.34452903270000...</td>\n",
       "      <td>Article</td>\n",
       "      <td>21.716202</td>\n",
       "      <td>-51.373856</td>\n",
       "      <td>0.106212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11786</th>\n",
       "      <td>Statoil</td>\n",
       "      <td>2004-04-30</td>\n",
       "      <td>Partitioning of semi-soluble organic compounds...</td>\n",
       "      <td>[-2.4629395008, 3.9331054688, -4.4266467094, 0...</td>\n",
       "      <td>Article</td>\n",
       "      <td>-26.765224</td>\n",
       "      <td>31.264029</td>\n",
       "      <td>0.106574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Affiliate       Date  \\\n",
       "15074        NaN        NaT   \n",
       "6261   Petrobras 2010-01-30   \n",
       "10610      Shell 2014-04-30   \n",
       "7743     Statoil 1999-04-30   \n",
       "7538         Eni 2008-02-15   \n",
       "3838       Exxon 2000-06-30   \n",
       "14934        NaN        NaT   \n",
       "15285        NaN        NaT   \n",
       "10502      Shell 2012-06-30   \n",
       "14497        NaN        NaT   \n",
       "9249     Statoil 1992-04-30   \n",
       "8649       Exxon 1989-04-30   \n",
       "5066       Shell 1989-04-30   \n",
       "14812        NaN        NaT   \n",
       "5556       Shell 2018-08-01   \n",
       "10727      Total 2014-03-31   \n",
       "12750      Shell 2001-12-31   \n",
       "5751       Shell 2011-12-31   \n",
       "6422       Total 2008-07-31   \n",
       "11786    Statoil 2004-04-30   \n",
       "\n",
       "                                             Description  \\\n",
       "15074                                                oil   \n",
       "6261   Advanced performance evaluation of a reverse o...   \n",
       "10610  Economics of steam-assisted gravity drainage f...   \n",
       "7743   Chemical and Ecotoxicological Characterisation...   \n",
       "7538          Structure of waxy crude oil emulsion gels    \n",
       "3838   Characterizing PM2.5 emission profiles for sta...   \n",
       "14934                                     classification   \n",
       "15285                                     produced water   \n",
       "10502  Well-to-wake energy and greenhouse gas analysi...   \n",
       "14497                                          petroleum   \n",
       "9249   IOR resource potential of Norwegian North Sea ...   \n",
       "8649   BEB-operated thermal projects: Comparison of p...   \n",
       "5066   BEB-operated thermal projects: Comparison of p...   \n",
       "14812                                       liquefaction   \n",
       "5556   The effect of oxygenate fuels on PN emissions ...   \n",
       "10727  High pressure viscosity characterization of fo...   \n",
       "12750  Aqueous leaching of polycyclic aromatic hydroc...   \n",
       "5751   Demonstrating the fuel economy potential of pa...   \n",
       "6422                Filterability of oil sands tailings    \n",
       "11786  Partitioning of semi-soluble organic compounds...   \n",
       "\n",
       "                                                 Doc2Vec  Type_vec     TSNE_1  \\\n",
       "15074  [-0.4282711744, 2.7900283337, -2.6506662369000...  Keywords  23.724588   \n",
       "6261   [0.1258293688, 6.7627344131000005, -6.18596124...   Article  -0.898239   \n",
       "10610  [-0.6078539491, 3.3439757824, -4.8164253235, -...   Article -19.555229   \n",
       "7743   [-3.4217646122, 3.2996394634, -6.9708566666, -...   Article -31.787167   \n",
       "7538   [-0.1932552606, 3.2740831375, -1.7274987698, -...   Article  24.381937   \n",
       "3838   [-2.3404331207, 7.1500716209, -6.321516037, 0....   Article  -0.975951   \n",
       "14934  [-3.6147005558, 4.3121452332, -4.9571299553, -...  Keywords -31.555269   \n",
       "15285  [-1.1359440088000001, 3.6240203381000002, -4.9...  Keywords -34.611584   \n",
       "10502  [-1.0872951746, 4.3649663925, -5.7739739418, 2...   Article  -0.774618   \n",
       "14497  [-0.2437291741, 3.0880243778, -1.3117181063, -...  Keywords  23.377129   \n",
       "9249   [0.5740600824000001, 6.1507005692, -1.58802568...   Article  24.581907   \n",
       "8649   [-1.8900097609, 6.6728649139, -3.799053669, 0....   Article -61.596748   \n",
       "5066   [-1.6470646858, 6.555706501, -3.76441764830000...   Article -61.593414   \n",
       "14812  [0.9881038666, 2.7050681114, -1.1644713879, -0...  Keywords  23.251734   \n",
       "5556   [-1.5451220274000002, 2.6626803875, -8.0992641...   Article  -1.872740   \n",
       "10727  [1.3301105499, 2.3850858212, -2.1765749454, -0...   Article  25.023630   \n",
       "12750  [-1.3535658121, 2.0455274582, -3.5550067425, 0...   Article  36.183414   \n",
       "5751   [-4.2701740265, 5.058816433, -5.986205101, 0.9...   Article -58.066982   \n",
       "6422   [1.0330308676, 2.9685220718, -1.34452903270000...   Article  21.716202   \n",
       "11786  [-2.4629395008, 3.9331054688, -4.4266467094, 0...   Article -26.765224   \n",
       "\n",
       "          TSNE_2  DisQuery  \n",
       "15074 -54.072781  0.000000  \n",
       "6261   -9.343952  0.048916  \n",
       "10610 -19.973049  0.049188  \n",
       "7743   26.226465  0.058726  \n",
       "7538  -54.424145  0.062128  \n",
       "3838   -9.051226  0.064043  \n",
       "14934  26.176226  0.069877  \n",
       "15285  27.184467  0.072928  \n",
       "10502  -9.366707  0.072934  \n",
       "14497 -54.102676  0.080275  \n",
       "9249  -56.005833  0.081228  \n",
       "8649   -6.843457  0.082111  \n",
       "5066   -6.847637  0.083048  \n",
       "14812 -54.073257  0.089425  \n",
       "5556   -9.519087  0.092262  \n",
       "10727 -53.527313  0.097174  \n",
       "12750 -29.160728  0.101593  \n",
       "5751   -5.225783  0.104546  \n",
       "6422  -51.373856  0.106212  \n",
       "11786  31.264029  0.106574  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizando uma consulta de acordo com a coluna \"Description\" \n",
    "# e retornando os N vetores mais próximos\n",
    "query = \"oil\"   #Termo consultado\n",
    "n_answer = 20     #Número de respostas\n",
    "\n",
    "# Indentificando o vetor da query\n",
    "query_vector = multi_vector[multi_vector[\"Description\"] == query][\"Doc2Vec\"].values[0]\n",
    "\n",
    "#Criando um Dataframe para a query\n",
    "multi_vector_query = multi_vector \n",
    "\n",
    "#Acrescentando uma coluna com as distâncias e selecionando o N mais próximos\n",
    "multi_vector_query[\"DisQuery\"] = (multi_vector[\"Doc2Vec\"].\n",
    "                                  apply(lambda x: distance.\n",
    "                                        cosine(x , query_vector)))\n",
    "multi_vector_query = (multi_vector_query.nsmallest(n_answer, \"DisQuery\")\n",
    "                      .sort_values(\"DisQuery\"))\n",
    "multi_vector_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o grafico\n",
    "scater_plot([multi_vector_query[\"TSNE_1\"],multi_vector_query[\"TSNE_2\"]], \n",
    "            multi_vector_query[\"Description\"], \n",
    "            'CornflowerBlue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
