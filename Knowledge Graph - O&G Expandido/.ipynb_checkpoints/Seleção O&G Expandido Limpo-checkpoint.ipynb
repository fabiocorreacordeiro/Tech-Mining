{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import ast\n",
    "from xml.dom import minidom\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando dataframe com Vetores, Keywords e com os artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_json(\"Elsevier_abstract - Keywords.json\")\n",
    "Keywords_1000 = pd.read_json(\"Keywords_1000.json\")\n",
    "multi_vector = pd.read_csv(\"Elsevier_abstract - Multivector.csv\")\n",
    "consolidado = pd.read_json(\"Elsevier_abstract - Consolidado.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179548"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(consolidado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao ler o arquivo \"Elsevier_abstract - Multivector.csv\" os valores da coluna \"Doc2Vec\" vem como string e não como uma lista. Portanto usamos a função \"ast.literal_eval\" para converter a string em lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_vector[\"Doc2Vec\"] = multi_vector[\"Doc2Vec\"].apply(ast.literal_eval) #Convertendo string em list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após selecionar as keywords mais representativas do domínio que se busca, será identificado os artigos mais próximos dessas keywords. Primeiramente será identificado o artigo mais próximo de cada uma das keyword, em seguida seleciona-se o segundo artigo mais próximo e assim sucessivamente. Caso um artigo já tenha sido selecionado, passa-se para o artigo mais próximo que ainda não tenha sido selecionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords selecionadas\n",
    "queries = Keywords_1000['Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Keywords selecionadas:  969\n"
     ]
    }
   ],
   "source": [
    "print (\"Número de Keywords selecionadas: \", len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cicle:  0\n",
      "cicle:  1\n",
      "cicle:  2\n",
      "cicle:  3\n",
      "cicle:  4\n",
      "Tempo total decorrido:  7:54:00.250000\n"
     ]
    }
   ],
   "source": [
    "momentoInicial = datetime.datetime.now()   # Inicia um contador do tempo\n",
    "\n",
    "new_corpus = []        # Lista com artigos selecionados\n",
    "number_article = 10   # Número de artigos apagados por Keyword por ciclo\n",
    "cicles = 5\n",
    "\n",
    "\n",
    "for m in range(cicles): # number_article): # Iterando para selecionar os m artigos mais próximos de cada query\n",
    "    print(\"cicle: \", m)\n",
    "    \n",
    "   \n",
    "    for query in queries: # Iterando sobre cada Keyword selecionada\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # Realizando uma consulta de acordo com a coluna \"Description\" \n",
    "            # e retornando os N vetores mais próximos\n",
    "\n",
    "            # Indentificando o vetor da query\n",
    "            query_vector = multi_vector[multi_vector[\"Description\"] == query][\"Doc2Vec\"].values[0]\n",
    "\n",
    "            #Acrescentando uma coluna com as distâncias e ordenando pela distÂncia\n",
    "            multi_vector[\"DisQuery\"] = (multi_vector[\"Doc2Vec\"].\n",
    "                                        apply(lambda x: distance.\n",
    "                                              cosine(x , query_vector)))\n",
    "            multi_vector = multi_vector.sort_values(\"DisQuery\")\n",
    "            \n",
    "            # Apagando os n artigos mais distante\n",
    "            multi_vector = multi_vector.drop(multi_vector           \n",
    "                                             .tail(number_article)\n",
    "                                             .index)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "momentoFinal = datetime.datetime.now() #Encerrando o contador do tempo\n",
    "print(\"Tempo total decorrido: \", momentoFinal - momentoInicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Affiliate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Date</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Raw_text</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Publisher Summary\\n            \\...</td>\n",
       "      <td>None</td>\n",
       "      <td>[AMERICAN HEALTH FOUNDATION, , LEWIS, BARRY, B...</td>\n",
       "      <td>10.1016/B978-0-12-103450-4.50008-4</td>\n",
       "      <td>1980-12-31</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Workshop Report: Clinical-Pathological Section</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n            Publisher Summary\\n            \\...</td>\n",
       "      <td>Exxon</td>\n",
       "      <td>[AMERICAN HEALTH FOUNDATION, , BLACKBURN, HENR...</td>\n",
       "      <td>10.1016/B978-0-12-103450-4.50007-2</td>\n",
       "      <td>1980-12-31</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Workshop Report: Epidemiological Section</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>\\n               Abstract\\n               \\n  ...</td>\n",
       "      <td>BP International</td>\n",
       "      <td>[Lebrun, A, Bignan, G, Szabo, J.L, Arenas-Carr...</td>\n",
       "      <td>10.1016/S0168-9002(00)00296-5</td>\n",
       "      <td>2000-07-01</td>\n",
       "      <td>[Spectrometry, CdZnTe, Nuclear spent fuels]</td>\n",
       "      <td></td>\n",
       "      <td>Gamma spectrometric characterization of short ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>\\n               Résumé\\n               \\n    ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[Zaghba, N., Yassine, N., Bakhatar, A., Bahlao...</td>\n",
       "      <td>10.1016/j.reval.2012.01.005</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>[Syndrome de Buckley, Hyperimmunoglobulinémie ...</td>\n",
       "      <td></td>\n",
       "      <td>Syndrome de Buckley associé à un syndrome de D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>\\n               Abstract\\n               \\n  ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[Simkins, Lauren M., Simms, Alexander R., Crus...</td>\n",
       "      <td>10.1016/j.palaeo.2012.05.024</td>\n",
       "      <td>2012-08-15</td>\n",
       "      <td>[Magnetic susceptibility, Holocene climate, 8....</td>\n",
       "      <td></td>\n",
       "      <td>Correlation of early and mid-Holocene events u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Abstract         Affiliate  \\\n",
       "0      \\n            Publisher Summary\\n            \\...              None   \n",
       "1      \\n            Publisher Summary\\n            \\...             Exxon   \n",
       "100    \\n               Abstract\\n               \\n  ...  BP International   \n",
       "1000   \\n               Résumé\\n               \\n    ...              None   \n",
       "10000  \\n               Abstract\\n               \\n  ...              None   \n",
       "\n",
       "                                                 Creator  \\\n",
       "0      [AMERICAN HEALTH FOUNDATION, , LEWIS, BARRY, B...   \n",
       "1      [AMERICAN HEALTH FOUNDATION, , BLACKBURN, HENR...   \n",
       "100    [Lebrun, A, Bignan, G, Szabo, J.L, Arenas-Carr...   \n",
       "1000   [Zaghba, N., Yassine, N., Bakhatar, A., Bahlao...   \n",
       "10000  [Simkins, Lauren M., Simms, Alexander R., Crus...   \n",
       "\n",
       "                                      DOI       Date  \\\n",
       "0      10.1016/B978-0-12-103450-4.50008-4 1980-12-31   \n",
       "1      10.1016/B978-0-12-103450-4.50007-2 1980-12-31   \n",
       "100         10.1016/S0168-9002(00)00296-5 2000-07-01   \n",
       "1000          10.1016/j.reval.2012.01.005 2012-06-30   \n",
       "10000        10.1016/j.palaeo.2012.05.024 2012-08-15   \n",
       "\n",
       "                                                Keywords Raw_text  \\\n",
       "0                                                     []            \n",
       "1                                                     []            \n",
       "100          [Spectrometry, CdZnTe, Nuclear spent fuels]            \n",
       "1000   [Syndrome de Buckley, Hyperimmunoglobulinémie ...            \n",
       "10000  [Magnetic susceptibility, Holocene climate, 8....            \n",
       "\n",
       "                                                   Title  \n",
       "0        Workshop Report: Clinical-Pathological Section   \n",
       "1              Workshop Report: Epidemiological Section   \n",
       "100    Gamma spectrometric characterization of short ...  \n",
       "1000   Syndrome de Buckley associé à un syndrome de D...  \n",
       "10000  Correlation of early and mid-Holocene events u...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidado['Selecionados'] = consolidado['Title'].apply(lambda x: x in multi_vector[\"Description\"].tolist())\n",
    "novo_consolidado = consolidado[consolidado['Selecionados'] == True]\n",
    "del novo_consolidado['Selecionados']\n",
    "novo_consolidado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120030"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novo_consolidado.to_json('Elsevier_abstract - O&G expandido limpo.json', date_format = 'iso')\n",
    "len(novo_consolidado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
